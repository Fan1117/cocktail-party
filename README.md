# Seeing Through Noise: Speaker Separation and Enhancement using Visually-derived Speech
Implementation of the methods described in the paper: [Seeing Through Noise: Speaker Separation and Enhancement using Visually-derived Speech](http://www.vision.huji.ac.il/speaker-separation) by Aviv Gabbay, Ariel Ephrat, Tavi Halperin and Shmuel Peleg.

## Speaker Separation and Enhancement Demo
<a href="http://www.youtube.com/watch?feature=player_embedded&v=qmsyj7vAzoI" target="_blank">
<img src="http://img.youtube.com/vi/qmsyj7vAzoI/0.jpg" width="480" height="360" />
</a>

## Usage
### Dependencies
* python >= 2.7
* [mediaio](https://github.com/avivga/mediaio)
* [face-detection](https://github.com/avivga/face-detection)
* keras >= 2.0.4
* numpy >= 1.12.1
* dlib >= 19.4.0
* opencv >= 3.2.0

## Citing
If you find this project useful for your research, please cite
```
@inproceedings{gabbay2018seeing,
  author    = {Aviv Gabbay and
               Ariel Ephrat and
               Tavi Halperin and
               Shmuel Peleg},
  title     = {Seeing Through Noise: Visually Driven Speaker Separation And Enhancement},
  booktitle = {{ICASSP}},
  pages     = {3051--3055},
  publisher = {{IEEE}},
  year      = {2018}
}
```

